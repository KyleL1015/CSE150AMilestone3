{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CSE150A Milestone 3: Multinomial HMM for Weather Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing and Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgRxL1RzV4_P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from hmmlearn import hmm\n",
        "from hmmlearn.hmm import GaussianHMM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from scipy.stats import mode\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv('seattle-weather.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuTIueMWWOuf"
      },
      "outputs": [],
      "source": [
        "#discretize weather\n",
        "def discretize_weather(w):\n",
        "    if w == 'drizzle': return 0\n",
        "    elif w == 'rain': return 1\n",
        "    elif w == 'sun': return 2\n",
        "    elif w == 'snow': return 3\n",
        "    elif w == 'fog': return 4\n",
        "\n",
        "df['weather_cat'] = df['weather'].apply(discretize_weather)\n",
        "\n",
        "#make sure typing is correct\n",
        "df['weather_cat'] = df['weather_cat'].astype(int)\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IR6Y5Qt0WTCn",
        "outputId": "8b09511e-6b97-4189-8466-4ded1c693caa"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-Z94q_0WTiN"
      },
      "outputs": [],
      "source": [
        "#dropping the values for date and weather for easier processing\n",
        "df.drop(['date', 'weather'], axis=1, inplace=True)\n",
        "df = df.dropna()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qcs7Yj3AWwV9"
      },
      "outputs": [],
      "source": [
        "#discrete values check\n",
        "print(df['weather_cat'].unique())  # Should be [0, 1, 2, 3, 4]\n",
        "\n",
        "#map for weather\n",
        "weather_map = {0: 'drizzle', 1: 'rain', 2: 'sun', 3: 'snow', 4: 'fog'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Get a single feature vector for obs/labels\n",
        "X = df[['precipitation', 'temp_max', 'temp_min', 'wind']].values #observations\n",
        "Y = df['weather_cat'].values\n",
        "\n",
        "#split training and test data\n",
        "X_train, X_test ,Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "#Define and train the Gaussian HMM\n",
        "n_states = 5\n",
        "model = GaussianHMM(n_components=n_states, covariance_type=\"diag\", n_iter=1000, random_state=42)\n",
        "model.fit(X_train)\n",
        "\n",
        "#Code written colaboratively and taken from Chat GPT-4o:\n",
        "#Prompt: I asked Chatgpt why the accuracy for the GaussianHMM was so bad before, and it suggested not using the discrete mapping we had initially which was interefering with our accuracy\n",
        "#Predict hidden states for the test set\n",
        "predicted_states_train = model.predict(X_train)\n",
        "\n",
        "print(\"Transition matrix:\\n\", model.transmat_)  # Probability of moving between states\n",
        "print(\"\\nMeans of each state:\\n\", model.means_)  # Average values for each feature in each state\n",
        "print(\"\\nCovariances:\\n\", model.covars_)  # Variability in each state\n",
        "\n",
        "#Map each hidden state to the most common label in training data\n",
        "state_to_label = {}\n",
        "for state in range(n_states):\n",
        "    mask = (predicted_states_train == state)  # Find all samples assigned to this state\n",
        "    if np.sum(mask) > 0:  # Avoid empty clusters\n",
        "        state_to_label[state] = mode(Y_train[mask]).mode[0]\n",
        "\n",
        "#Convert hidden states to predicted weather labels\n",
        "mapped_predictions = np.array([state_to_label[state] for state in predicted_states_train])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Training data summary\n",
        "conf_matrix_train = confusion_matrix(Y_train, mapped_predictions)\n",
        "accuracy_train = accuracy_score(Y_train, mapped_predictions)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_train)\n",
        "print(\"\\nAccuracy Score:\", accuracy_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Graph for training data\n",
        "wlabels_train = [weather_map[label] for label in Y_train]\n",
        "plt.figure(figsize = (20,10))\n",
        "plt.plot(predicted_states_train, label=\"Predicted Hidden States\")\n",
        "plt.plot(wlabels_train, label=\"Actual Weather Labels\", linestyle=\"dashed\")\n",
        "plt.title(\"Actual vs. Predicted Weather for Training Data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Now use the model on the test set\n",
        "predicted_states_test = model.predict(X_test)\n",
        "mapped_predictions_test = np.array([state_to_label[state] for state in predicted_states_test])\n",
        "\n",
        "#Test data summary\n",
        "conf_matrix_test = confusion_matrix(Y_test, mapped_predictions_test)\n",
        "accuracy_test = accuracy_score(Y_test, mapped_predictions_test)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_test)\n",
        "print(\"\\nAccuracy Score:\", accuracy_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Graph for test data\n",
        "wlabels_test = [weather_map[label] for label in Y_test]\n",
        "plt.figure(figsize = (20,10))\n",
        "plt.plot(predicted_states_test, label=\"Predicted Hidden States\")\n",
        "plt.plot(wlabels_test, label=\"Actual Weather Labels\", linestyle=\"dashed\")\n",
        "plt.title(\"Actual vs. Predicted Weather for Testing Data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPVmzQV2X7PHIa0CnJipai2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tensorflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
